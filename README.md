# Awesome AI Keyboard Warrior

This repository contains research on using AI to control computers solely through the mouse and keyboard.

<p align="center">
  <strong><a href="#1">Papers</a></strong> â€¢
  <strong><a href="#2">Simulation Environments & Benchmarks</a></strong> â€¢
  <strong><a href="#3">Auxiliary Tools</a></strong>
</p>

<a href="https://github.com/unikcc/Awesome-AI-Keyboard-Warrior">
  <img src="https://img.shields.io/badge/AIKeyboardWarrirr-0.1-blue" alt="Awesome-AI-Keyboard-Warrior">
</a>
<a href="https://huggingface.co/docs/transformers/index" rel="nofollow">
  <img src="https://img.shields.io/github/last-commit/unikcc/Awesome-AI-Keyboard-Warrior?color=orange" alt="Awesome-AI-Keyboard-Warrior">
</a>
<a href="https://github.com/unikcc/Awesome-AI-Keyboard-Warrior" rel="nofollow">
  <img src="https://img.shields.io/badge/PRs-Welcome-green" alt="Welcome">
</a>
<a href="https://github.com/unikcc/Awesome-AI-Keyboard-Warrior/blob/master/LICENSE" rel="nofollow">
  <img src="https://img.shields.io/badge/LICENSE-MIT-cyan" alt="LICENSE">
</a>


## ðŸ”” News
- **2023-02-15** We created a new repository dedicated to exploring the topic of "Human-like AI Control: Operating Computers with Mouse and Keyboard," aptly named "AI Keyboard Warrior" (AIé”®ç›˜ä¾ ).

---

<h2 id="1">ðŸ“œ Papers </h2>
<ol>

<li> <strong>A data-driven approach for learning to control computers</strong> Peter C Humphreys, David Raposo, Tobias Pohlen, Gregory Thornton, Rachita Chhaparia, Alistair Muldal, Josh Abramson, Petko Georgiev, Adam Santoro, Timothy Lillicrap*, 
ICML, 2022, [<a href="https://proceedings.mlr.press/v162/humphreys22a.html">Paper</a>]</li>

<li><strong>Video PreTraining (VPT): Learning to Act by Watching Unlabeled Online Videos</strong> *Bowen Baker, Ilge Akkaya, Peter Zhokhov, Joost Huizinga, Jie Tang, Adrien Ecoffet, Brandon Houghton, Raul Sampedro, Jeff Clune*, NeurIPS, 2022, [<a href="https://openreview.net/forum?id=AXDNM76T1nc">Paper</a>], [<a href="https://github.com/openai/Video-Pre-Training">Code</a>]</li>

<li><strong>MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge</strong> *Linxi Fan, Guanzhi Wang, Yunfan Jiang, Ajay Mandlekar, Yuncong Yang, Haoyi Zhu, Andrew Tang, De-An Huang, Yuke Zhu, Anima Anandkumar*, NeurIPS, <strong>Outstanding paper</strong>, 2022, [<a href="https://openreview.net/forum?id=rc8o_j8I8PX">Paper</a>], [<a href="https://github.com/MineDojo/MineDojo">Code</a>], [<a href="https://minedojo.org/">Demo</a>]</li>

<li><strong> Do As I Can, Not As I Say:
Grounding Language in Robotic Affordances </strong> Michael Ahnâˆ—, Anthony Brohanâˆ—, Noah Brownâˆ—, Yevgen Chebotarâˆ—, Omar Cortes, et al, Arxiv, 2022, [<a href="https://arxiv.org/pdf/2204.01691.pdf">Paper</a>], [<a href="https://say-can.github.io/">Demo</a>]</li>

<li><strong>WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents</strong> *Shunyu Yao, Howard Chen, John Yang, Karthik Narasimhan*, NeurIPS, 2022 [<a href="https://openreview.net/forum?id=R9KnuFlvnU">Paper</a>], [<a href="https://github.com/princeton-nlp/WebShop">Code</a>], [<a href="https://webshop-pnlp.github.io/">Demo</a>]</li>

<li><strong>Do BERTs Learn to Use Browser User Interface? Exploring Multi-Step Tasks with Unified Vision-and-Language BERTs</strong> *Taichi Ik, Akiko Aizawa*, Arxiv, [<a href="https://arxiv.org/abs/2203.07828">Paper</a>]</li>

<li><strong>Reinforcement Learning on Web Interfaces using Workflow-Guided Exploration</strong> *Evan Zheran Liu, Kelvin Guu, Panupong Pasupat, Tianlin Shi, Percy Liang*, ICLR, 2018, [<a href="https://openreview.net/forum?id=ryTp3f-0-">Paper</a>]</li>

<li><strong>World of Bits: An Open-Domain Platform for Web-Based Agents</strong> *Tianlin Shi, Andrej Karpathy, Linxi Fan, Jonathan Hernandez, Percy Liang*, ICML, 2017, [<a href="https://proceedings.mlr.press/v70/shi17a.html">Paper</a>]</li>

</ol>

<h2 id="2">ðŸŽ® Simulation Environment && Benchmark</h2>

1. MiniWoB++: A web interaction benchmark for reinforcement learning [[Site](https://github.com/Farama-Foundation/miniwob-plusplus)]


2. MineRL Dataset:  Towards AI in Minecraft, [[Site](https://minerl.io/dataset/)]

3. WebShop: Towards real-world web interaction with grounded language agents [[Site](https://webshop-pnlp.github.io/)]

4. MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge [[Site](https://minedojo.org/)]


<h2 id="3">ðŸš€ Auxiliary Tool </h2>

1. Sandbox2: Generates sandboxes for C/C++ libraries automatically [[Project Site](https://github.com/google/sandboxed-api/tree/main/sandboxed_api/sandbox2)]

2. Chrome Webdriver Security Considerations [[Project Site](https://chromedriver.chromium.org/security-considerations)]

3. MCP-Reborn: an MCP (Mod Coder Pack) for Minecraft for making modded clients and researching its code. (1.13-1.19.2) [[Project Site](https://github.com/Hexeption/MCP-Reborn)]


## ðŸ’–Acknowledgments

This project uses some code adapted from the following repositories:

- [awesome-embodied-vision](https://github.com/ChanganVR/awesome-embodied-vision)
- [Chain-of-ThoughtsPapers](https://github.com/zjunlp/Prompt4ReasoningPapers)


